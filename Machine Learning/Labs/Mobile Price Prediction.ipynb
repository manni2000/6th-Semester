{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8e77a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aa9d209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Model</th>\n",
       "      <th>Storage</th>\n",
       "      <th>RAM</th>\n",
       "      <th>Screen Size (inches)</th>\n",
       "      <th>Camera (MP)</th>\n",
       "      <th>Battery Capacity (mAh)</th>\n",
       "      <th>Price ($)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple</td>\n",
       "      <td>iPhone 13 Pro</td>\n",
       "      <td>128 GB</td>\n",
       "      <td>6 GB</td>\n",
       "      <td>6.1</td>\n",
       "      <td>12 + 12 + 12</td>\n",
       "      <td>3095</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Samsung</td>\n",
       "      <td>Galaxy S21 Ultra</td>\n",
       "      <td>256 GB</td>\n",
       "      <td>12 GB</td>\n",
       "      <td>6.8</td>\n",
       "      <td>108 + 10 + 10 + 12</td>\n",
       "      <td>5000</td>\n",
       "      <td>1199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OnePlus</td>\n",
       "      <td>9 Pro</td>\n",
       "      <td>128 GB</td>\n",
       "      <td>8 GB</td>\n",
       "      <td>6.7</td>\n",
       "      <td>48 + 50 + 8 + 2</td>\n",
       "      <td>4500</td>\n",
       "      <td>899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xiaomi</td>\n",
       "      <td>Redmi Note 10 Pro</td>\n",
       "      <td>128 GB</td>\n",
       "      <td>6 GB</td>\n",
       "      <td>6.67</td>\n",
       "      <td>64 + 8 + 5 + 2</td>\n",
       "      <td>5020</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google</td>\n",
       "      <td>Pixel 6</td>\n",
       "      <td>128 GB</td>\n",
       "      <td>8 GB</td>\n",
       "      <td>6.4</td>\n",
       "      <td>50 + 12.2</td>\n",
       "      <td>4614</td>\n",
       "      <td>799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>Samsung</td>\n",
       "      <td>Galaxy Note20 5G</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>12+64+12</td>\n",
       "      <td>4300</td>\n",
       "      <td>1049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>Xiaomi</td>\n",
       "      <td>Mi 10 Lite 5G</td>\n",
       "      <td>128</td>\n",
       "      <td>6</td>\n",
       "      <td>6.57</td>\n",
       "      <td>48+8+2+2</td>\n",
       "      <td>4160</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>Apple</td>\n",
       "      <td>iPhone 12 Pro Max</td>\n",
       "      <td>128</td>\n",
       "      <td>6</td>\n",
       "      <td>6.7</td>\n",
       "      <td>12+12+12</td>\n",
       "      <td>3687</td>\n",
       "      <td>1099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>Oppo</td>\n",
       "      <td>Reno3</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>48+13+8+2</td>\n",
       "      <td>4025</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>Samsung</td>\n",
       "      <td>Galaxy S10 Lite</td>\n",
       "      <td>128</td>\n",
       "      <td>6</td>\n",
       "      <td>6.7</td>\n",
       "      <td>48+12+5</td>\n",
       "      <td>4500</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>407 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Brand              Model Storage    RAM Screen Size (inches)  \\\n",
       "0      Apple      iPhone 13 Pro  128 GB   6 GB                  6.1   \n",
       "1    Samsung   Galaxy S21 Ultra  256 GB  12 GB                  6.8   \n",
       "2    OnePlus              9 Pro  128 GB   8 GB                  6.7   \n",
       "3     Xiaomi  Redmi Note 10 Pro  128 GB   6 GB                 6.67   \n",
       "4     Google            Pixel 6  128 GB   8 GB                  6.4   \n",
       "..       ...                ...     ...    ...                  ...   \n",
       "402  Samsung   Galaxy Note20 5G     128      8                  6.7   \n",
       "403   Xiaomi      Mi 10 Lite 5G     128      6                 6.57   \n",
       "404    Apple  iPhone 12 Pro Max     128      6                  6.7   \n",
       "405     Oppo              Reno3     128      8                  6.4   \n",
       "406  Samsung    Galaxy S10 Lite     128      6                  6.7   \n",
       "\n",
       "            Camera (MP)  Battery Capacity (mAh) Price ($)  \n",
       "0          12 + 12 + 12                    3095       999  \n",
       "1    108 + 10 + 10 + 12                    5000      1199  \n",
       "2       48 + 50 + 8 + 2                    4500       899  \n",
       "3        64 + 8 + 5 + 2                    5020       279  \n",
       "4             50 + 12.2                    4614       799  \n",
       "..                  ...                     ...       ...  \n",
       "402            12+64+12                    4300      1049  \n",
       "403            48+8+2+2                    4160       349  \n",
       "404            12+12+12                    3687      1099  \n",
       "405           48+13+8+2                    4025       429  \n",
       "406             48+12+5                    4500       649  \n",
       "\n",
       "[407 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobile=pd.read_csv('Mobile phone price - Mobile phone price.csv')\n",
    "mobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b6f8573",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile['Storage']=[int(str.replace(\"GB\",\"\").strip()) for str in mobile['Storage'] ]\n",
    "mobile['RAM']=[int(str.replace(\"GB\",\"\").replace(\" \",\"\")) for str in mobile['RAM'] ]\n",
    "mobile['Screen Size (inches)']=[float(str.replace(\"(unfolded)\",\"\").replace(\" \",\"\").replace(\"6.8+3.9\",\"10.7\")) for str in mobile['Screen Size (inches)']]\n",
    "mobile['Price ($)']=[int(str.replace('$',\"\").replace(\" \",\"\").replace(',',\"\")) for str in mobile['Price ($)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07528eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile['Camera (MP)']=[str.replace(\"MP\",\"\").replace(\" \",\"\") for str in mobile['Camera (MP)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3f7bd8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Model</th>\n",
       "      <th>Storage</th>\n",
       "      <th>RAM</th>\n",
       "      <th>Screen Size (inches)</th>\n",
       "      <th>Camera (MP)</th>\n",
       "      <th>Battery Capacity (mAh)</th>\n",
       "      <th>Price ($)</th>\n",
       "      <th>Camera-1</th>\n",
       "      <th>Camera-2</th>\n",
       "      <th>Camera-3</th>\n",
       "      <th>Camera-4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple</td>\n",
       "      <td>iPhone 13 Pro</td>\n",
       "      <td>128</td>\n",
       "      <td>6</td>\n",
       "      <td>6.10</td>\n",
       "      <td>12+12+12</td>\n",
       "      <td>3095</td>\n",
       "      <td>999</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Samsung</td>\n",
       "      <td>Galaxy S21 Ultra</td>\n",
       "      <td>256</td>\n",
       "      <td>12</td>\n",
       "      <td>6.80</td>\n",
       "      <td>108+10+10+12</td>\n",
       "      <td>5000</td>\n",
       "      <td>1199</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OnePlus</td>\n",
       "      <td>9 Pro</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>6.70</td>\n",
       "      <td>48+50+8+2</td>\n",
       "      <td>4500</td>\n",
       "      <td>899</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xiaomi</td>\n",
       "      <td>Redmi Note 10 Pro</td>\n",
       "      <td>128</td>\n",
       "      <td>6</td>\n",
       "      <td>6.67</td>\n",
       "      <td>64+8+5+2</td>\n",
       "      <td>5020</td>\n",
       "      <td>279</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google</td>\n",
       "      <td>Pixel 6</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>6.40</td>\n",
       "      <td>50+12.2</td>\n",
       "      <td>4614</td>\n",
       "      <td>799</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>Samsung</td>\n",
       "      <td>Galaxy Note20 5G</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>6.70</td>\n",
       "      <td>12+64+12</td>\n",
       "      <td>4300</td>\n",
       "      <td>1049</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>Xiaomi</td>\n",
       "      <td>Mi 10 Lite 5G</td>\n",
       "      <td>128</td>\n",
       "      <td>6</td>\n",
       "      <td>6.57</td>\n",
       "      <td>48+8+2+2</td>\n",
       "      <td>4160</td>\n",
       "      <td>349</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>Apple</td>\n",
       "      <td>iPhone 12 Pro Max</td>\n",
       "      <td>128</td>\n",
       "      <td>6</td>\n",
       "      <td>6.70</td>\n",
       "      <td>12+12+12</td>\n",
       "      <td>3687</td>\n",
       "      <td>1099</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>Oppo</td>\n",
       "      <td>Reno3</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>6.40</td>\n",
       "      <td>48+13+8+2</td>\n",
       "      <td>4025</td>\n",
       "      <td>429</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>Samsung</td>\n",
       "      <td>Galaxy S10 Lite</td>\n",
       "      <td>128</td>\n",
       "      <td>6</td>\n",
       "      <td>6.70</td>\n",
       "      <td>48+12+5</td>\n",
       "      <td>4500</td>\n",
       "      <td>649</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>407 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Brand              Model  Storage  RAM  Screen Size (inches)  \\\n",
       "0      Apple      iPhone 13 Pro      128    6                  6.10   \n",
       "1    Samsung   Galaxy S21 Ultra      256   12                  6.80   \n",
       "2    OnePlus              9 Pro      128    8                  6.70   \n",
       "3     Xiaomi  Redmi Note 10 Pro      128    6                  6.67   \n",
       "4     Google            Pixel 6      128    8                  6.40   \n",
       "..       ...                ...      ...  ...                   ...   \n",
       "402  Samsung   Galaxy Note20 5G      128    8                  6.70   \n",
       "403   Xiaomi      Mi 10 Lite 5G      128    6                  6.57   \n",
       "404    Apple  iPhone 12 Pro Max      128    6                  6.70   \n",
       "405     Oppo              Reno3      128    8                  6.40   \n",
       "406  Samsung    Galaxy S10 Lite      128    6                  6.70   \n",
       "\n",
       "      Camera (MP)  Battery Capacity (mAh)  Price ($) Camera-1 Camera-2  \\\n",
       "0        12+12+12                    3095        999                     \n",
       "1    108+10+10+12                    5000       1199                     \n",
       "2       48+50+8+2                    4500        899                     \n",
       "3        64+8+5+2                    5020        279                     \n",
       "4         50+12.2                    4614        799                     \n",
       "..            ...                     ...        ...      ...      ...   \n",
       "402      12+64+12                    4300       1049                     \n",
       "403      48+8+2+2                    4160        349                     \n",
       "404      12+12+12                    3687       1099                     \n",
       "405     48+13+8+2                    4025        429                     \n",
       "406       48+12+5                    4500        649                     \n",
       "\n",
       "    Camera-3 Camera-4  \n",
       "0                      \n",
       "1                      \n",
       "2                      \n",
       "3                      \n",
       "4                      \n",
       "..       ...      ...  \n",
       "402                    \n",
       "403                    \n",
       "404                    \n",
       "405                    \n",
       "406                    \n",
       "\n",
       "[407 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobile['Camera-1']=[\"\" for ind in mobile.index]\n",
    "mobile['Camera-2']=[\"\" for ind in mobile.index]\n",
    "mobile['Camera-3']=[\"\" for ind in mobile.index]\n",
    "mobile['Camera-4']=[\"\" for ind in mobile.index]\n",
    "mobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22f1cb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4170/1565452127.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mobile[f'Camera-{i}'][ind]+=ch\n"
     ]
    }
   ],
   "source": [
    "for ind in mobile.index :\n",
    "    i=1\n",
    "    for ch in mobile['Camera (MP)'][ind]:\n",
    "        if ch=='+':\n",
    "            i+=1\n",
    "        else :\n",
    "            mobile[f'Camera-{i}'][ind]+=ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4c7c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile['Camera-1']=[float(str if str!='' else '0') for str in mobile['Camera-1']]\n",
    "mobile['Camera-2']=[float(str if str!='' else '0') for str in mobile['Camera-2']]\n",
    "mobile['Camera-3']=[float(str if str!='' else '0') for str in mobile['Camera-3']]\n",
    "mobile['Camera-4']=[str.replace('3D','108').replace('ToF','64') for str in mobile['Camera-4']]\n",
    "mobile['Camera-4']=[float(str if str!='' else '0') for str in mobile['Camera-4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b65f1a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies=pd.get_dummies(mobile['Brand'])\n",
    "mobile=pd.concat([mobile,dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8893b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile.drop(['Brand','Model','Camera (MP)'],inplace=True,axis=1)\n",
    "y=mobile['Price ($)']\n",
    "x=mobile.drop(['Price ($)'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44d76608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee3941ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 15:44:41.383630: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-06 15:44:41.535614: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-06 15:44:41.535634: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-06 15:44:42.106824: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-06 15:44:42.106918: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-06 15:44:42.106926: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import Model,Input\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89ecf7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 15:44:42.689528: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-04-06 15:44:42.689554: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-04-06 15:44:42.689572: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (student12): /proc/driver/nvidia/version does not exist\n",
      "2023-04-06 15:44:42.689730: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "inp=Input(shape=(24,))\n",
    "l1=Dense(30,activation=\"tanh\")(inp)\n",
    "l2=Dense(10,activation=\"relu\")(l1)\n",
    "out=Dense(1,activation=\"linear\")(l2)\n",
    "model=Model(inputs=inp,outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e50aad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss=\"mse\",metrics=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b8759e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "11/11 [==============================] - 1s 17ms/step - loss: 261317.2656 - mse: 261317.2656 - val_loss: 235120.3906 - val_mse: 235120.3906\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 261013.7031 - mse: 261013.7031 - val_loss: 234886.5312 - val_mse: 234886.5312\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 260769.4844 - mse: 260769.4844 - val_loss: 234635.1719 - val_mse: 234635.1719\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 260507.3906 - mse: 260507.3906 - val_loss: 234361.7344 - val_mse: 234361.7344\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 260222.9219 - mse: 260222.9219 - val_loss: 234067.6406 - val_mse: 234067.6406\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 259915.8594 - mse: 259915.8594 - val_loss: 233748.8125 - val_mse: 233748.8125\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 259581.6406 - mse: 259581.6406 - val_loss: 233406.7344 - val_mse: 233406.7344\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 259220.5781 - mse: 259220.5781 - val_loss: 233033.7500 - val_mse: 233033.7500\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 258825.4844 - mse: 258825.4844 - val_loss: 232624.7812 - val_mse: 232624.7812\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 258407.1406 - mse: 258407.1406 - val_loss: 232192.6875 - val_mse: 232192.6875\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 257953.8906 - mse: 257953.8906 - val_loss: 231733.9062 - val_mse: 231733.9062\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 257483.8594 - mse: 257483.8594 - val_loss: 231246.5625 - val_mse: 231246.5625\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 256977.9375 - mse: 256977.9375 - val_loss: 230729.9062 - val_mse: 230729.9062\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 256452.8438 - mse: 256452.8438 - val_loss: 230199.2188 - val_mse: 230199.2188\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 255902.6250 - mse: 255902.6250 - val_loss: 229654.4219 - val_mse: 229654.4219\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 255333.7812 - mse: 255333.7812 - val_loss: 229066.0000 - val_mse: 229066.0000\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 254731.3906 - mse: 254731.3906 - val_loss: 228471.6094 - val_mse: 228471.6094\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 254125.6875 - mse: 254125.6875 - val_loss: 227836.4844 - val_mse: 227836.4844\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 253446.4688 - mse: 253446.4688 - val_loss: 227166.9531 - val_mse: 227166.9531\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 252765.6094 - mse: 252765.6094 - val_loss: 226472.7344 - val_mse: 226472.7344\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 252064.3906 - mse: 252064.3906 - val_loss: 225769.8125 - val_mse: 225769.8125\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 251344.0000 - mse: 251344.0000 - val_loss: 225032.9219 - val_mse: 225032.9219\n",
      "Epoch 23/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 250592.1406 - mse: 250592.1406 - val_loss: 224271.7031 - val_mse: 224271.7031\n",
      "Epoch 24/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 249809.6562 - mse: 249809.6562 - val_loss: 223487.4688 - val_mse: 223487.4688\n",
      "Epoch 25/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 249004.4531 - mse: 249004.4531 - val_loss: 222681.0938 - val_mse: 222681.0938\n",
      "Epoch 26/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 248184.1719 - mse: 248184.1719 - val_loss: 221849.9219 - val_mse: 221849.9219\n",
      "Epoch 27/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 247326.5781 - mse: 247326.5781 - val_loss: 220991.2500 - val_mse: 220991.2500\n",
      "Epoch 28/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 246441.8906 - mse: 246441.8906 - val_loss: 220099.0938 - val_mse: 220099.0938\n",
      "Epoch 29/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 245553.9688 - mse: 245553.9688 - val_loss: 219189.2188 - val_mse: 219189.2188\n",
      "Epoch 30/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 244619.2500 - mse: 244619.2500 - val_loss: 218286.9688 - val_mse: 218286.9688\n",
      "Epoch 31/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 243689.1094 - mse: 243689.1094 - val_loss: 217349.3594 - val_mse: 217349.3594\n",
      "Epoch 32/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 242723.6875 - mse: 242723.6875 - val_loss: 216397.7344 - val_mse: 216397.7344\n",
      "Epoch 33/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 241762.0156 - mse: 241762.0156 - val_loss: 215393.6562 - val_mse: 215393.6562\n",
      "Epoch 34/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 240721.2031 - mse: 240721.2031 - val_loss: 214371.2188 - val_mse: 214371.2188\n",
      "Epoch 35/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 239654.2500 - mse: 239654.2500 - val_loss: 213302.7344 - val_mse: 213302.7344\n",
      "Epoch 36/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 238553.7500 - mse: 238553.7500 - val_loss: 212227.6562 - val_mse: 212227.6562\n",
      "Epoch 37/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 237477.5312 - mse: 237477.5312 - val_loss: 211114.3438 - val_mse: 211114.3438\n",
      "Epoch 38/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 236334.0312 - mse: 236334.0312 - val_loss: 210011.5625 - val_mse: 210011.5625\n",
      "Epoch 39/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 235200.0312 - mse: 235200.0312 - val_loss: 208888.8125 - val_mse: 208888.8125\n",
      "Epoch 40/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 234063.2344 - mse: 234063.2344 - val_loss: 207735.4844 - val_mse: 207735.4844\n",
      "Epoch 41/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 232912.2500 - mse: 232912.2500 - val_loss: 206585.0781 - val_mse: 206585.0781\n",
      "Epoch 42/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 231732.4062 - mse: 231732.4062 - val_loss: 205421.1406 - val_mse: 205421.1406\n",
      "Epoch 43/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 230548.0625 - mse: 230548.0625 - val_loss: 204222.7031 - val_mse: 204222.7031\n",
      "Epoch 44/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 229299.1562 - mse: 229299.1562 - val_loss: 202989.8750 - val_mse: 202989.8750\n",
      "Epoch 45/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 228072.5156 - mse: 228072.5156 - val_loss: 201754.7188 - val_mse: 201754.7188\n",
      "Epoch 46/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 226816.0938 - mse: 226816.0938 - val_loss: 200540.8125 - val_mse: 200540.8125\n",
      "Epoch 47/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 225587.0938 - mse: 225587.0938 - val_loss: 199280.5625 - val_mse: 199280.5625\n",
      "Epoch 48/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 224301.1250 - mse: 224301.1250 - val_loss: 198048.0938 - val_mse: 198048.0938\n",
      "Epoch 49/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 223031.9688 - mse: 223031.9688 - val_loss: 196793.6719 - val_mse: 196793.6719\n",
      "Epoch 50/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 221770.7812 - mse: 221770.7812 - val_loss: 195509.5781 - val_mse: 195509.5781\n",
      "Epoch 51/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 220463.3125 - mse: 220463.3125 - val_loss: 194212.7031 - val_mse: 194212.7188\n",
      "Epoch 52/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 219131.0781 - mse: 219131.0781 - val_loss: 192873.9844 - val_mse: 192873.9844\n",
      "Epoch 53/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 217757.9062 - mse: 217757.9062 - val_loss: 191536.2500 - val_mse: 191536.2500\n",
      "Epoch 54/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 216411.8906 - mse: 216411.8906 - val_loss: 190174.2500 - val_mse: 190174.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 215020.3125 - mse: 215020.3125 - val_loss: 188797.8750 - val_mse: 188797.8750\n",
      "Epoch 56/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 213615.5312 - mse: 213615.5312 - val_loss: 187405.1406 - val_mse: 187405.1406\n",
      "Epoch 57/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 212171.7656 - mse: 212171.7656 - val_loss: 185966.8125 - val_mse: 185966.8125\n",
      "Epoch 58/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 210748.8281 - mse: 210748.8281 - val_loss: 184540.3594 - val_mse: 184540.3594\n",
      "Epoch 59/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 209324.7031 - mse: 209324.7031 - val_loss: 183144.6875 - val_mse: 183144.6875\n",
      "Epoch 60/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 207928.2969 - mse: 207928.2969 - val_loss: 181791.5156 - val_mse: 181791.5156\n",
      "Epoch 61/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 206520.5938 - mse: 206520.5938 - val_loss: 180412.3125 - val_mse: 180412.3125\n",
      "Epoch 62/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 205111.9062 - mse: 205111.9062 - val_loss: 178998.6094 - val_mse: 178998.6094\n",
      "Epoch 63/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 203673.6406 - mse: 203673.6406 - val_loss: 177596.5781 - val_mse: 177596.5781\n",
      "Epoch 64/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 202256.6875 - mse: 202256.6875 - val_loss: 176214.8125 - val_mse: 176214.8125\n",
      "Epoch 65/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 200868.2656 - mse: 200868.2656 - val_loss: 174831.0469 - val_mse: 174831.0469\n",
      "Epoch 66/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 199442.4844 - mse: 199442.4844 - val_loss: 173380.2969 - val_mse: 173380.2969\n",
      "Epoch 67/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 197984.6094 - mse: 197984.6094 - val_loss: 171980.9062 - val_mse: 171980.9062\n",
      "Epoch 68/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 196574.3281 - mse: 196574.3281 - val_loss: 170615.9219 - val_mse: 170615.9219\n",
      "Epoch 69/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 195194.9688 - mse: 195194.9688 - val_loss: 169226.2500 - val_mse: 169226.2500\n",
      "Epoch 70/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 193792.0312 - mse: 193792.0312 - val_loss: 167836.4375 - val_mse: 167836.4375\n",
      "Epoch 71/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 192314.0000 - mse: 192314.0000 - val_loss: 166345.0781 - val_mse: 166345.0781\n",
      "Epoch 72/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 190825.2656 - mse: 190825.2656 - val_loss: 164908.7344 - val_mse: 164908.7344\n",
      "Epoch 73/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 189362.9844 - mse: 189362.9844 - val_loss: 163463.5312 - val_mse: 163463.5312\n",
      "Epoch 74/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 187873.8906 - mse: 187873.8906 - val_loss: 162030.1875 - val_mse: 162030.1875\n",
      "Epoch 75/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 186458.4062 - mse: 186458.4062 - val_loss: 160624.4688 - val_mse: 160624.4688\n",
      "Epoch 76/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 185029.9688 - mse: 185029.9688 - val_loss: 159200.6406 - val_mse: 159200.6406\n",
      "Epoch 77/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 183613.2500 - mse: 183613.2500 - val_loss: 157792.1406 - val_mse: 157792.1406\n",
      "Epoch 78/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 182188.8125 - mse: 182188.8125 - val_loss: 156454.9688 - val_mse: 156454.9688\n",
      "Epoch 79/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 180812.3750 - mse: 180812.3750 - val_loss: 155107.1719 - val_mse: 155107.1719\n",
      "Epoch 80/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 179405.4375 - mse: 179405.4375 - val_loss: 153691.0625 - val_mse: 153691.0625\n",
      "Epoch 81/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 177983.2969 - mse: 177983.2969 - val_loss: 152212.9688 - val_mse: 152212.9688\n",
      "Epoch 82/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 176488.3906 - mse: 176488.3906 - val_loss: 150825.9844 - val_mse: 150825.9844\n",
      "Epoch 83/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 175089.5000 - mse: 175089.5000 - val_loss: 149424.0781 - val_mse: 149424.0781\n",
      "Epoch 84/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 173644.7812 - mse: 173644.7812 - val_loss: 148080.1250 - val_mse: 148080.1250\n",
      "Epoch 85/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 172318.2344 - mse: 172318.2344 - val_loss: 146720.5781 - val_mse: 146720.5781\n",
      "Epoch 86/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 170926.3438 - mse: 170926.3438 - val_loss: 145301.7344 - val_mse: 145301.7344\n",
      "Epoch 87/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 169494.7344 - mse: 169494.7344 - val_loss: 143987.0312 - val_mse: 143987.0312\n",
      "Epoch 88/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 168174.1719 - mse: 168174.1719 - val_loss: 142671.5312 - val_mse: 142671.5312\n",
      "Epoch 89/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 166811.3594 - mse: 166811.3594 - val_loss: 141354.7500 - val_mse: 141354.7500\n",
      "Epoch 90/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 165484.6719 - mse: 165484.6719 - val_loss: 140023.0156 - val_mse: 140023.0156\n",
      "Epoch 91/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 164125.9375 - mse: 164125.9375 - val_loss: 138730.4219 - val_mse: 138730.4219\n",
      "Epoch 92/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 162802.8125 - mse: 162802.8125 - val_loss: 137451.6875 - val_mse: 137451.6875\n",
      "Epoch 93/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 161509.5938 - mse: 161509.5938 - val_loss: 136159.5156 - val_mse: 136159.5156\n",
      "Epoch 94/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 160209.0312 - mse: 160209.0312 - val_loss: 134882.2188 - val_mse: 134882.2188\n",
      "Epoch 95/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 158926.3594 - mse: 158926.3594 - val_loss: 133624.9219 - val_mse: 133624.9219\n",
      "Epoch 96/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 157635.2188 - mse: 157635.2188 - val_loss: 132382.0781 - val_mse: 132382.0781\n",
      "Epoch 97/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 156378.4844 - mse: 156378.4844 - val_loss: 131092.7500 - val_mse: 131092.7500\n",
      "Epoch 98/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 155032.4844 - mse: 155032.4844 - val_loss: 129767.7109 - val_mse: 129767.7109\n",
      "Epoch 99/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 153671.0938 - mse: 153671.0938 - val_loss: 128515.7812 - val_mse: 128515.7812\n",
      "Epoch 100/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 152444.8438 - mse: 152444.8438 - val_loss: 127258.6953 - val_mse: 127258.6953\n",
      "Epoch 101/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 151159.5625 - mse: 151159.5625 - val_loss: 126029.7812 - val_mse: 126029.7812\n",
      "Epoch 102/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 149879.0469 - mse: 149879.0469 - val_loss: 124816.8203 - val_mse: 124816.8203\n",
      "Epoch 103/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 148619.6406 - mse: 148619.6406 - val_loss: 123533.6797 - val_mse: 123533.6797\n",
      "Epoch 104/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 147335.5469 - mse: 147335.5469 - val_loss: 122271.2891 - val_mse: 122271.2891\n",
      "Epoch 105/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 146066.1875 - mse: 146066.1875 - val_loss: 121108.5234 - val_mse: 121108.5234\n",
      "Epoch 106/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 144896.0000 - mse: 144896.0000 - val_loss: 119939.0391 - val_mse: 119939.0391\n",
      "Epoch 107/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 143717.5938 - mse: 143717.5938 - val_loss: 118766.2188 - val_mse: 118766.2188\n",
      "Epoch 108/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 142523.1406 - mse: 142523.1406 - val_loss: 117650.5859 - val_mse: 117650.5859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 141416.0312 - mse: 141416.0312 - val_loss: 116491.8516 - val_mse: 116491.8516\n",
      "Epoch 110/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 140255.1875 - mse: 140255.1875 - val_loss: 115399.0000 - val_mse: 115399.0000\n",
      "Epoch 111/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 139138.6406 - mse: 139138.6406 - val_loss: 114317.8516 - val_mse: 114317.8516\n",
      "Epoch 112/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 138047.0625 - mse: 138047.0625 - val_loss: 113256.1719 - val_mse: 113256.1719\n",
      "Epoch 113/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 136954.4688 - mse: 136954.4688 - val_loss: 112252.0703 - val_mse: 112252.0703\n",
      "Epoch 114/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 135920.8125 - mse: 135920.8125 - val_loss: 111240.0469 - val_mse: 111240.0469\n",
      "Epoch 115/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 134873.3594 - mse: 134873.3594 - val_loss: 110178.3672 - val_mse: 110178.3672\n",
      "Epoch 116/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 133733.8906 - mse: 133733.8906 - val_loss: 109144.4531 - val_mse: 109144.4531\n",
      "Epoch 117/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 132679.0469 - mse: 132679.0469 - val_loss: 108036.0469 - val_mse: 108036.0469\n",
      "Epoch 118/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 131613.2500 - mse: 131613.2500 - val_loss: 107048.5625 - val_mse: 107048.5625\n",
      "Epoch 119/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 130626.6094 - mse: 130626.6094 - val_loss: 106146.1719 - val_mse: 106146.1719\n",
      "Epoch 120/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 129707.6797 - mse: 129707.6797 - val_loss: 105221.2891 - val_mse: 105221.2891\n",
      "Epoch 121/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 128774.7578 - mse: 128774.7578 - val_loss: 104346.5000 - val_mse: 104346.5000\n",
      "Epoch 122/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 127873.4297 - mse: 127873.4297 - val_loss: 103484.3203 - val_mse: 103484.3203\n",
      "Epoch 123/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 126961.3047 - mse: 126961.3047 - val_loss: 102526.6562 - val_mse: 102526.6562\n",
      "Epoch 124/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 125993.5859 - mse: 125993.5859 - val_loss: 101630.1562 - val_mse: 101630.1562\n",
      "Epoch 125/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 125084.9375 - mse: 125084.9375 - val_loss: 100733.6875 - val_mse: 100733.6875\n",
      "Epoch 126/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 124191.1250 - mse: 124191.1250 - val_loss: 99860.4688 - val_mse: 99860.4688\n",
      "Epoch 127/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 123308.5625 - mse: 123308.5625 - val_loss: 99064.7891 - val_mse: 99064.7891\n",
      "Epoch 128/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 122457.6484 - mse: 122457.6484 - val_loss: 98238.9453 - val_mse: 98238.9453\n",
      "Epoch 129/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 121632.3672 - mse: 121632.3672 - val_loss: 97434.4297 - val_mse: 97434.4297\n",
      "Epoch 130/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 120844.0391 - mse: 120844.0391 - val_loss: 96690.1953 - val_mse: 96690.1953\n",
      "Epoch 131/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 120083.8047 - mse: 120083.8047 - val_loss: 95951.1016 - val_mse: 95951.1016\n",
      "Epoch 132/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 119305.5859 - mse: 119305.5859 - val_loss: 95171.7500 - val_mse: 95171.7500\n",
      "Epoch 133/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 118502.5234 - mse: 118502.5234 - val_loss: 94467.2891 - val_mse: 94467.2891\n",
      "Epoch 134/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 117757.5156 - mse: 117757.5156 - val_loss: 93708.9219 - val_mse: 93708.9219\n",
      "Epoch 135/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 117021.7734 - mse: 117021.7734 - val_loss: 92977.8984 - val_mse: 92977.8984\n",
      "Epoch 136/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 116275.4609 - mse: 116275.4609 - val_loss: 92313.8047 - val_mse: 92313.8047\n",
      "Epoch 137/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 115601.8125 - mse: 115601.8125 - val_loss: 91656.6562 - val_mse: 91656.6562\n",
      "Epoch 138/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 114950.7812 - mse: 114950.7812 - val_loss: 91050.5469 - val_mse: 91050.5469\n",
      "Epoch 139/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 114298.2891 - mse: 114298.2891 - val_loss: 90435.0703 - val_mse: 90435.0703\n",
      "Epoch 140/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 113638.0156 - mse: 113638.0156 - val_loss: 89756.0391 - val_mse: 89756.0391\n",
      "Epoch 141/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 112932.8750 - mse: 112932.8750 - val_loss: 89041.0938 - val_mse: 89041.0938\n",
      "Epoch 142/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 112265.9688 - mse: 112265.9688 - val_loss: 88389.9219 - val_mse: 88389.9219\n",
      "Epoch 143/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 111559.4453 - mse: 111559.4453 - val_loss: 87835.4609 - val_mse: 87835.4609\n",
      "Epoch 144/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 111000.7969 - mse: 111000.7969 - val_loss: 87313.2109 - val_mse: 87313.2109\n",
      "Epoch 145/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 110404.3438 - mse: 110404.3438 - val_loss: 86715.3438 - val_mse: 86715.3438\n",
      "Epoch 146/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 109841.9922 - mse: 109841.9922 - val_loss: 86158.6953 - val_mse: 86158.6953\n",
      "Epoch 147/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 109297.4141 - mse: 109297.4141 - val_loss: 85648.1328 - val_mse: 85648.1328\n",
      "Epoch 148/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 108763.3125 - mse: 108763.3125 - val_loss: 85133.2266 - val_mse: 85133.2266\n",
      "Epoch 149/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 108222.7656 - mse: 108222.7656 - val_loss: 84648.2656 - val_mse: 84648.2656\n",
      "Epoch 150/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 107748.9375 - mse: 107748.9375 - val_loss: 84178.8438 - val_mse: 84178.8438\n",
      "Epoch 151/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 107255.8438 - mse: 107255.8438 - val_loss: 83704.2891 - val_mse: 83704.2891\n",
      "Epoch 152/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 106776.0859 - mse: 106776.0859 - val_loss: 83238.8984 - val_mse: 83238.8984\n",
      "Epoch 153/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 106264.7500 - mse: 106264.7500 - val_loss: 82806.2109 - val_mse: 82806.2109\n",
      "Epoch 154/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 105784.1250 - mse: 105784.1250 - val_loss: 82329.1250 - val_mse: 82329.1250\n",
      "Epoch 155/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 105316.1719 - mse: 105316.1719 - val_loss: 81888.3594 - val_mse: 81888.3594\n",
      "Epoch 156/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 104883.7891 - mse: 104883.7891 - val_loss: 81476.5156 - val_mse: 81476.5156\n",
      "Epoch 157/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 104422.3516 - mse: 104422.3516 - val_loss: 81053.8516 - val_mse: 81053.8516\n",
      "Epoch 158/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 104000.8359 - mse: 104000.8359 - val_loss: 80659.4531 - val_mse: 80659.4531\n",
      "Epoch 159/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 103626.9453 - mse: 103626.9453 - val_loss: 80286.8203 - val_mse: 80286.8203\n",
      "Epoch 160/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 103235.7109 - mse: 103235.7109 - val_loss: 79941.1094 - val_mse: 79941.1094\n",
      "Epoch 161/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 102883.1641 - mse: 102883.1641 - val_loss: 79620.1094 - val_mse: 79620.1094\n",
      "Epoch 162/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 102550.8516 - mse: 102550.8516 - val_loss: 79290.3906 - val_mse: 79290.3906\n",
      "Epoch 163/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step - loss: 102216.6797 - mse: 102216.6797 - val_loss: 78972.7656 - val_mse: 78972.7656\n",
      "Epoch 164/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 101863.7109 - mse: 101863.7109 - val_loss: 78681.1250 - val_mse: 78681.1250\n",
      "Epoch 165/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 101548.6016 - mse: 101548.6016 - val_loss: 78406.1562 - val_mse: 78406.1562\n",
      "Epoch 166/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 101228.9766 - mse: 101228.9766 - val_loss: 78075.4609 - val_mse: 78075.4609\n",
      "Epoch 167/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 100898.4375 - mse: 100898.4375 - val_loss: 77755.5078 - val_mse: 77755.5078\n",
      "Epoch 168/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 100599.5938 - mse: 100599.5938 - val_loss: 77498.6172 - val_mse: 77498.6172\n",
      "Epoch 169/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 100316.5469 - mse: 100316.5469 - val_loss: 77257.7891 - val_mse: 77257.7891\n",
      "Epoch 170/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 100067.9062 - mse: 100067.9062 - val_loss: 77003.8438 - val_mse: 77003.8438\n",
      "Epoch 171/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 99797.8750 - mse: 99797.8750 - val_loss: 76749.2578 - val_mse: 76749.2578\n",
      "Epoch 172/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 99522.9219 - mse: 99522.9219 - val_loss: 76497.0703 - val_mse: 76497.0703\n",
      "Epoch 173/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 99284.5156 - mse: 99284.5156 - val_loss: 76253.3281 - val_mse: 76253.3359\n",
      "Epoch 174/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 98993.5781 - mse: 98993.5781 - val_loss: 76034.2812 - val_mse: 76034.2812\n",
      "Epoch 175/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 98774.9688 - mse: 98774.9688 - val_loss: 75824.6562 - val_mse: 75824.6562\n",
      "Epoch 176/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 98518.1016 - mse: 98518.1016 - val_loss: 75596.2031 - val_mse: 75596.2031\n",
      "Epoch 177/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 98322.8516 - mse: 98322.8516 - val_loss: 75387.4453 - val_mse: 75387.4453\n",
      "Epoch 178/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 98083.1484 - mse: 98083.1484 - val_loss: 75201.8516 - val_mse: 75201.8516\n",
      "Epoch 179/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 97914.8828 - mse: 97914.8828 - val_loss: 75042.0781 - val_mse: 75042.0781\n",
      "Epoch 180/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 97737.5703 - mse: 97737.5703 - val_loss: 74891.9688 - val_mse: 74891.9688\n",
      "Epoch 181/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 97587.7969 - mse: 97587.7969 - val_loss: 74733.6016 - val_mse: 74733.6016\n",
      "Epoch 182/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 97406.6953 - mse: 97406.6953 - val_loss: 74566.9844 - val_mse: 74566.9844\n",
      "Epoch 183/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 97228.8594 - mse: 97228.8594 - val_loss: 74425.0234 - val_mse: 74425.0234\n",
      "Epoch 184/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 97090.8281 - mse: 97090.8281 - val_loss: 74314.0938 - val_mse: 74314.0938\n",
      "Epoch 185/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 96955.6641 - mse: 96955.6641 - val_loss: 74202.6328 - val_mse: 74202.6328\n",
      "Epoch 186/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 96848.5078 - mse: 96848.5078 - val_loss: 74091.0000 - val_mse: 74091.0000\n",
      "Epoch 187/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 96707.7266 - mse: 96707.7266 - val_loss: 73978.2812 - val_mse: 73978.2812\n",
      "Epoch 188/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 96615.1172 - mse: 96615.1172 - val_loss: 73839.9922 - val_mse: 73839.9922\n",
      "Epoch 189/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 96445.1406 - mse: 96445.1406 - val_loss: 73734.5938 - val_mse: 73734.5938\n",
      "Epoch 190/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 96327.0859 - mse: 96327.0859 - val_loss: 73620.5703 - val_mse: 73620.5703\n",
      "Epoch 191/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 96209.2891 - mse: 96209.2891 - val_loss: 73489.0547 - val_mse: 73489.0547\n",
      "Epoch 192/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 96056.5156 - mse: 96056.5156 - val_loss: 73386.1797 - val_mse: 73386.1797\n",
      "Epoch 193/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 95950.4688 - mse: 95950.4688 - val_loss: 73294.9062 - val_mse: 73294.9062\n",
      "Epoch 194/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 95858.8125 - mse: 95858.8125 - val_loss: 73223.3125 - val_mse: 73223.3125\n",
      "Epoch 195/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 95782.3047 - mse: 95782.3047 - val_loss: 73141.0000 - val_mse: 73141.0000\n",
      "Epoch 196/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 95695.5547 - mse: 95695.5547 - val_loss: 73085.1562 - val_mse: 73085.1562\n",
      "Epoch 197/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 95630.3359 - mse: 95630.3359 - val_loss: 73030.5000 - val_mse: 73030.5000\n",
      "Epoch 198/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 95563.4375 - mse: 95563.4375 - val_loss: 72968.1328 - val_mse: 72968.1328\n",
      "Epoch 199/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 95500.6172 - mse: 95500.6172 - val_loss: 72922.2188 - val_mse: 72922.2188\n",
      "Epoch 200/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 95454.3906 - mse: 95454.3906 - val_loss: 72874.6797 - val_mse: 72874.6797\n",
      "Epoch 201/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 95386.6953 - mse: 95386.6953 - val_loss: 72807.1016 - val_mse: 72807.1016\n",
      "Epoch 202/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 95306.0312 - mse: 95306.0312 - val_loss: 72750.2656 - val_mse: 72750.2656\n",
      "Epoch 203/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 95239.9141 - mse: 95239.9141 - val_loss: 72691.8281 - val_mse: 72691.8281\n",
      "Epoch 204/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 95170.6797 - mse: 95170.6797 - val_loss: 72634.6797 - val_mse: 72634.6797\n",
      "Epoch 205/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 95103.7812 - mse: 95103.7812 - val_loss: 72571.1250 - val_mse: 72571.1250\n",
      "Epoch 206/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 95038.9297 - mse: 95038.9297 - val_loss: 72523.8438 - val_mse: 72523.8438\n",
      "Epoch 207/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94986.8984 - mse: 94986.8984 - val_loss: 72485.3672 - val_mse: 72485.3672\n",
      "Epoch 208/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 94942.9062 - mse: 94942.9062 - val_loss: 72443.3594 - val_mse: 72443.3594\n",
      "Epoch 209/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94888.4062 - mse: 94888.4062 - val_loss: 72409.7734 - val_mse: 72409.7734\n",
      "Epoch 210/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 94853.2344 - mse: 94853.2344 - val_loss: 72362.7109 - val_mse: 72362.7109\n",
      "Epoch 211/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94805.2422 - mse: 94805.2422 - val_loss: 72335.1406 - val_mse: 72335.1406\n",
      "Epoch 212/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94770.3203 - mse: 94770.3203 - val_loss: 72297.0938 - val_mse: 72297.0938\n",
      "Epoch 213/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94726.4922 - mse: 94726.4922 - val_loss: 72275.9062 - val_mse: 72275.9062\n",
      "Epoch 214/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94676.0859 - mse: 94676.0859 - val_loss: 72228.9297 - val_mse: 72228.9297\n",
      "Epoch 215/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94639.7266 - mse: 94639.7266 - val_loss: 72180.9141 - val_mse: 72180.9141\n",
      "Epoch 216/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94583.4844 - mse: 94583.4844 - val_loss: 72152.5078 - val_mse: 72152.5078\n",
      "Epoch 217/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94548.6172 - mse: 94548.6172 - val_loss: 72125.2500 - val_mse: 72125.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94514.9219 - mse: 94514.9219 - val_loss: 72111.8750 - val_mse: 72111.8750\n",
      "Epoch 219/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94501.9844 - mse: 94501.9844 - val_loss: 72094.3047 - val_mse: 72094.3047\n",
      "Epoch 220/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94483.1797 - mse: 94483.1797 - val_loss: 72082.6562 - val_mse: 72082.6562\n",
      "Epoch 221/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 94457.4219 - mse: 94457.4219 - val_loss: 72068.1250 - val_mse: 72068.1250\n",
      "Epoch 222/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94446.2812 - mse: 94446.2812 - val_loss: 72054.8281 - val_mse: 72054.8281\n",
      "Epoch 223/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94424.1016 - mse: 94424.1016 - val_loss: 72040.0391 - val_mse: 72040.0391\n",
      "Epoch 224/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94413.1719 - mse: 94413.1719 - val_loss: 72027.7656 - val_mse: 72027.7656\n",
      "Epoch 225/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 94392.0391 - mse: 94392.0391 - val_loss: 72005.5312 - val_mse: 72005.5312\n",
      "Epoch 226/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94358.7656 - mse: 94358.7656 - val_loss: 71998.2969 - val_mse: 71998.2969\n",
      "Epoch 227/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 94351.8203 - mse: 94351.8203 - val_loss: 71989.7422 - val_mse: 71989.7422\n",
      "Epoch 228/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94335.2812 - mse: 94335.2812 - val_loss: 71974.0234 - val_mse: 71974.0234\n",
      "Epoch 229/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94313.1484 - mse: 94313.1484 - val_loss: 71964.7109 - val_mse: 71964.7109\n",
      "Epoch 230/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 94291.9062 - mse: 94291.9062 - val_loss: 71947.7109 - val_mse: 71947.7109\n",
      "Epoch 231/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94279.3125 - mse: 94279.3125 - val_loss: 71931.6875 - val_mse: 71931.6875\n",
      "Epoch 232/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94253.2109 - mse: 94253.2109 - val_loss: 71922.2812 - val_mse: 71922.2891\n",
      "Epoch 233/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94242.8359 - mse: 94242.8359 - val_loss: 71916.0469 - val_mse: 71916.0469\n",
      "Epoch 234/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94242.4375 - mse: 94242.4375 - val_loss: 71902.3203 - val_mse: 71902.3203\n",
      "Epoch 235/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94212.7109 - mse: 94212.7109 - val_loss: 71896.6328 - val_mse: 71896.6328\n",
      "Epoch 236/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94205.7109 - mse: 94205.7109 - val_loss: 71893.9766 - val_mse: 71893.9766\n",
      "Epoch 237/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94196.3438 - mse: 94196.3438 - val_loss: 71887.5000 - val_mse: 71887.5000\n",
      "Epoch 238/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94189.9141 - mse: 94189.9141 - val_loss: 71886.1641 - val_mse: 71886.1641\n",
      "Epoch 239/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94184.7969 - mse: 94184.7969 - val_loss: 71881.6797 - val_mse: 71881.6797\n",
      "Epoch 240/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94192.1875 - mse: 94192.1875 - val_loss: 71874.2891 - val_mse: 71874.2891\n",
      "Epoch 241/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94168.2109 - mse: 94168.2109 - val_loss: 71874.4375 - val_mse: 71874.4375\n",
      "Epoch 242/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94156.7344 - mse: 94156.7344 - val_loss: 71868.8594 - val_mse: 71868.8594\n",
      "Epoch 243/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94154.6953 - mse: 94154.6953 - val_loss: 71867.4297 - val_mse: 71867.4297\n",
      "Epoch 244/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94159.2734 - mse: 94159.2734 - val_loss: 71867.7422 - val_mse: 71867.7422\n",
      "Epoch 245/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94153.0469 - mse: 94153.0469 - val_loss: 71864.1797 - val_mse: 71864.1797\n",
      "Epoch 246/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94149.0859 - mse: 94149.0859 - val_loss: 71863.9844 - val_mse: 71863.9844\n",
      "Epoch 247/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94141.4375 - mse: 94141.4375 - val_loss: 71857.8203 - val_mse: 71857.8203\n",
      "Epoch 248/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94143.4453 - mse: 94143.4453 - val_loss: 71852.8516 - val_mse: 71852.8516\n",
      "Epoch 249/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94121.2031 - mse: 94121.2031 - val_loss: 71851.6719 - val_mse: 71851.6719\n",
      "Epoch 250/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94119.4766 - mse: 94119.4766 - val_loss: 71850.7500 - val_mse: 71850.7500\n",
      "Epoch 251/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94114.1484 - mse: 94114.1484 - val_loss: 71849.8359 - val_mse: 71849.8359\n",
      "Epoch 252/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94114.5234 - mse: 94114.5234 - val_loss: 71849.9609 - val_mse: 71849.9609\n",
      "Epoch 253/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94116.0703 - mse: 94116.0703 - val_loss: 71848.5234 - val_mse: 71848.5234\n",
      "Epoch 254/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94107.7656 - mse: 94107.7656 - val_loss: 71846.8906 - val_mse: 71846.8906\n",
      "Epoch 255/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94104.0000 - mse: 94104.0000 - val_loss: 71846.1797 - val_mse: 71846.1797\n",
      "Epoch 256/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94099.5234 - mse: 94099.5234 - val_loss: 71845.6328 - val_mse: 71845.6328\n",
      "Epoch 257/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94098.7422 - mse: 94098.7422 - val_loss: 71845.3203 - val_mse: 71845.3203\n",
      "Epoch 258/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 94097.1016 - mse: 94097.1016 - val_loss: 71844.6797 - val_mse: 71844.6797\n",
      "Epoch 259/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94093.9219 - mse: 94093.9219 - val_loss: 71844.4766 - val_mse: 71844.4766\n",
      "Epoch 260/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 94090.7031 - mse: 94090.7031 - val_loss: 71844.1406 - val_mse: 71844.1406\n",
      "Epoch 261/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 94087.1406 - mse: 94087.1406 - val_loss: 71844.1562 - val_mse: 71844.1562\n",
      "Epoch 262/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94086.4531 - mse: 94086.4531 - val_loss: 71844.1641 - val_mse: 71844.1641\n",
      "Epoch 263/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94083.7656 - mse: 94083.7656 - val_loss: 71844.1875 - val_mse: 71844.1875\n",
      "Epoch 264/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94087.3047 - mse: 94087.3047 - val_loss: 71844.1562 - val_mse: 71844.1562\n",
      "Epoch 265/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94088.5391 - mse: 94088.5391 - val_loss: 71844.1562 - val_mse: 71844.1562\n",
      "Epoch 266/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94086.5078 - mse: 94086.5078 - val_loss: 71844.2422 - val_mse: 71844.2422\n",
      "Epoch 267/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 94089.9531 - mse: 94089.9531 - val_loss: 71844.1953 - val_mse: 71844.1953\n",
      "Epoch 268/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 94090.1562 - mse: 94090.1562 - val_loss: 71844.1562 - val_mse: 71844.1562\n",
      "Epoch 269/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94088.5625 - mse: 94088.5625 - val_loss: 71844.3281 - val_mse: 71844.3281\n",
      "Epoch 270/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94076.2891 - mse: 94076.2891 - val_loss: 71844.9453 - val_mse: 71844.9453\n",
      "Epoch 271/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94078.5078 - mse: 94078.5078 - val_loss: 71845.2578 - val_mse: 71845.2578\n",
      "Epoch 272/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 94071.5859 - mse: 94071.5859 - val_loss: 71846.7891 - val_mse: 71846.7891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 273/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94070.9766 - mse: 94070.9766 - val_loss: 71849.4844 - val_mse: 71849.4844\n",
      "Epoch 274/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94068.2891 - mse: 94068.2891 - val_loss: 71851.0938 - val_mse: 71851.0938\n",
      "Epoch 275/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 94068.0312 - mse: 94068.0312 - val_loss: 71850.6797 - val_mse: 71850.6797\n",
      "Epoch 276/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94068.1328 - mse: 94068.1328 - val_loss: 71849.4688 - val_mse: 71849.4688\n",
      "Epoch 277/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94078.7969 - mse: 94078.7969 - val_loss: 71847.4531 - val_mse: 71847.4531\n",
      "Epoch 278/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94074.5859 - mse: 94074.5859 - val_loss: 71848.1719 - val_mse: 71848.1719\n",
      "Epoch 279/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94071.6172 - mse: 94071.6172 - val_loss: 71848.0859 - val_mse: 71848.0859\n",
      "Epoch 280/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 94072.1797 - mse: 94072.1797 - val_loss: 71848.1953 - val_mse: 71848.1953\n",
      "Epoch 281/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94071.6562 - mse: 94071.6562 - val_loss: 71848.3203 - val_mse: 71848.3203\n",
      "Epoch 282/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94074.7656 - mse: 94074.7656 - val_loss: 71849.5938 - val_mse: 71849.5938\n",
      "Epoch 283/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94069.4922 - mse: 94069.4922 - val_loss: 71851.4609 - val_mse: 71851.4609\n",
      "Epoch 284/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94074.9297 - mse: 94074.9297 - val_loss: 71853.7891 - val_mse: 71853.7891\n",
      "Epoch 285/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94065.8203 - mse: 94065.8203 - val_loss: 71852.7422 - val_mse: 71852.7422\n",
      "Epoch 286/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94074.2188 - mse: 94074.2188 - val_loss: 71850.6094 - val_mse: 71850.6094\n",
      "Epoch 287/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94068.6562 - mse: 94068.6562 - val_loss: 71852.0703 - val_mse: 71852.0703\n",
      "Epoch 288/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94078.9688 - mse: 94078.9688 - val_loss: 71850.1484 - val_mse: 71850.1484\n",
      "Epoch 289/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94069.5781 - mse: 94069.5781 - val_loss: 71850.4922 - val_mse: 71850.4922\n",
      "Epoch 290/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94085.0859 - mse: 94085.0859 - val_loss: 71848.2344 - val_mse: 71848.2344\n",
      "Epoch 291/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94073.6719 - mse: 94073.6719 - val_loss: 71848.8906 - val_mse: 71848.8906\n",
      "Epoch 292/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94070.7578 - mse: 94070.7578 - val_loss: 71850.3516 - val_mse: 71850.3516\n",
      "Epoch 293/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94083.2031 - mse: 94083.2031 - val_loss: 71852.3906 - val_mse: 71852.3906\n",
      "Epoch 294/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94067.2969 - mse: 94067.2969 - val_loss: 71850.6953 - val_mse: 71850.6953\n",
      "Epoch 295/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94070.1562 - mse: 94070.1562 - val_loss: 71849.4297 - val_mse: 71849.4297\n",
      "Epoch 296/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94070.3359 - mse: 94070.3359 - val_loss: 71848.7344 - val_mse: 71848.7344\n",
      "Epoch 297/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94071.0547 - mse: 94071.0547 - val_loss: 71849.9844 - val_mse: 71849.9844\n",
      "Epoch 298/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94071.1406 - mse: 94071.1406 - val_loss: 71849.3281 - val_mse: 71849.3281\n",
      "Epoch 299/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 94070.5938 - mse: 94070.5938 - val_loss: 71849.2188 - val_mse: 71849.2188\n",
      "Epoch 300/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94070.4922 - mse: 94070.4922 - val_loss: 71848.9141 - val_mse: 71848.9141\n",
      "Epoch 301/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94071.0781 - mse: 94071.0781 - val_loss: 71847.2656 - val_mse: 71847.2656\n",
      "Epoch 302/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94070.7891 - mse: 94070.7891 - val_loss: 71846.3047 - val_mse: 71846.3047\n",
      "Epoch 303/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94078.9141 - mse: 94078.9141 - val_loss: 71845.3672 - val_mse: 71845.3672\n",
      "Epoch 304/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94078.2188 - mse: 94078.2188 - val_loss: 71845.6484 - val_mse: 71845.6484\n",
      "Epoch 305/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94083.6953 - mse: 94083.6953 - val_loss: 71848.4219 - val_mse: 71848.4219\n",
      "Epoch 306/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94070.8906 - mse: 94070.8906 - val_loss: 71849.5469 - val_mse: 71849.5469\n",
      "Epoch 307/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94074.4531 - mse: 94074.4531 - val_loss: 71850.8516 - val_mse: 71850.8516\n",
      "Epoch 308/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94071.5156 - mse: 94071.5156 - val_loss: 71849.5938 - val_mse: 71849.5938\n",
      "Epoch 309/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94069.5625 - mse: 94069.5625 - val_loss: 71849.5938 - val_mse: 71849.5938\n",
      "Epoch 310/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94072.0000 - mse: 94072.0000 - val_loss: 71850.7578 - val_mse: 71850.7578\n",
      "Epoch 311/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94071.5156 - mse: 94071.5156 - val_loss: 71850.4375 - val_mse: 71850.4375\n",
      "Epoch 312/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 94071.0938 - mse: 94071.0938 - val_loss: 71848.7969 - val_mse: 71848.7969\n",
      "Epoch 313/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94073.3594 - mse: 94073.3594 - val_loss: 71847.8125 - val_mse: 71847.8125\n",
      "Epoch 314/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94072.9219 - mse: 94072.9219 - val_loss: 71847.1484 - val_mse: 71847.1484\n",
      "Epoch 315/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94076.3359 - mse: 94076.3359 - val_loss: 71846.1094 - val_mse: 71846.1094\n",
      "Epoch 316/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94075.0859 - mse: 94075.0859 - val_loss: 71845.8594 - val_mse: 71845.8594\n",
      "Epoch 317/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94079.2188 - mse: 94079.2188 - val_loss: 71845.8516 - val_mse: 71845.8516\n",
      "Epoch 318/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94074.2188 - mse: 94074.2188 - val_loss: 71847.7891 - val_mse: 71847.7891\n",
      "Epoch 319/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94073.2109 - mse: 94073.2109 - val_loss: 71849.0859 - val_mse: 71849.0859\n",
      "Epoch 320/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94071.9844 - mse: 94071.9844 - val_loss: 71848.4609 - val_mse: 71848.4609\n",
      "Epoch 321/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94080.7109 - mse: 94080.7109 - val_loss: 71847.1953 - val_mse: 71847.1953\n",
      "Epoch 322/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94074.6250 - mse: 94074.6250 - val_loss: 71850.3281 - val_mse: 71850.3281\n",
      "Epoch 323/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94074.1406 - mse: 94074.1406 - val_loss: 71851.1797 - val_mse: 71851.1797\n",
      "Epoch 324/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94071.0000 - mse: 94071.0000 - val_loss: 71852.0938 - val_mse: 71852.0938\n",
      "Epoch 325/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94068.5391 - mse: 94068.5391 - val_loss: 71851.5312 - val_mse: 71851.5312\n",
      "Epoch 326/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94071.1172 - mse: 94071.1172 - val_loss: 71849.2109 - val_mse: 71849.2109\n",
      "Epoch 327/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94076.0234 - mse: 94076.0234 - val_loss: 71847.4609 - val_mse: 71847.4609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 328/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94070.6719 - mse: 94070.6719 - val_loss: 71847.9297 - val_mse: 71847.9297\n",
      "Epoch 329/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94073.4609 - mse: 94073.4609 - val_loss: 71846.7578 - val_mse: 71846.7578\n",
      "Epoch 330/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94073.7734 - mse: 94073.7734 - val_loss: 71847.1250 - val_mse: 71847.1250\n",
      "Epoch 331/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94077.4922 - mse: 94077.4922 - val_loss: 71846.8516 - val_mse: 71846.8516\n",
      "Epoch 332/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94073.0781 - mse: 94073.0781 - val_loss: 71846.8828 - val_mse: 71846.8828\n",
      "Epoch 333/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94075.0234 - mse: 94075.0234 - val_loss: 71847.7422 - val_mse: 71847.7422\n",
      "Epoch 334/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94074.2344 - mse: 94074.2344 - val_loss: 71847.7266 - val_mse: 71847.7266\n",
      "Epoch 335/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94074.7109 - mse: 94074.7109 - val_loss: 71847.7344 - val_mse: 71847.7344\n",
      "Epoch 336/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 94070.7500 - mse: 94070.7500 - val_loss: 71847.0234 - val_mse: 71847.0234\n",
      "Epoch 337/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94073.4453 - mse: 94073.4453 - val_loss: 71846.9922 - val_mse: 71846.9922\n",
      "Epoch 338/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94072.9844 - mse: 94072.9844 - val_loss: 71848.0391 - val_mse: 71848.0391\n",
      "Epoch 339/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94071.4766 - mse: 94071.4766 - val_loss: 71847.8984 - val_mse: 71847.8984\n",
      "Epoch 340/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94072.4766 - mse: 94072.4766 - val_loss: 71847.0391 - val_mse: 71847.0391\n",
      "Epoch 341/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94075.3750 - mse: 94075.3750 - val_loss: 71846.7422 - val_mse: 71846.7422\n",
      "Epoch 342/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94072.1797 - mse: 94072.1797 - val_loss: 71849.1172 - val_mse: 71849.1172\n",
      "Epoch 343/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 94070.5859 - mse: 94070.5859 - val_loss: 71849.2812 - val_mse: 71849.2812\n",
      "Epoch 344/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94071.8125 - mse: 94071.8125 - val_loss: 71850.2109 - val_mse: 71850.2109\n",
      "Epoch 345/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94069.4375 - mse: 94069.4375 - val_loss: 71850.7188 - val_mse: 71850.7188\n",
      "Epoch 346/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94071.6016 - mse: 94071.6016 - val_loss: 71850.0391 - val_mse: 71850.0391\n",
      "Epoch 347/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94071.6406 - mse: 94071.6406 - val_loss: 71849.5938 - val_mse: 71849.5938\n",
      "Epoch 348/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 94071.5469 - mse: 94071.5469 - val_loss: 71850.5703 - val_mse: 71850.5703\n",
      "Epoch 349/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94068.3906 - mse: 94068.3906 - val_loss: 71851.0391 - val_mse: 71851.0391\n",
      "Epoch 350/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94072.2734 - mse: 94072.2734 - val_loss: 71849.3203 - val_mse: 71849.3203\n",
      "Epoch 351/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94070.6250 - mse: 94070.6250 - val_loss: 71848.2656 - val_mse: 71848.2656\n",
      "Epoch 352/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94073.9531 - mse: 94073.9531 - val_loss: 71849.1953 - val_mse: 71849.1953\n",
      "Epoch 353/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94069.0000 - mse: 94069.0000 - val_loss: 71851.7266 - val_mse: 71851.7266\n",
      "Epoch 354/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94065.5625 - mse: 94065.5625 - val_loss: 71853.9844 - val_mse: 71853.9844\n",
      "Epoch 355/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94069.9297 - mse: 94069.9297 - val_loss: 71858.1797 - val_mse: 71858.1797\n",
      "Epoch 356/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94066.2422 - mse: 94066.2422 - val_loss: 71858.5938 - val_mse: 71858.5938\n",
      "Epoch 357/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 94063.2500 - mse: 94063.2500 - val_loss: 71857.1797 - val_mse: 71857.1797\n",
      "Epoch 358/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94066.7656 - mse: 94066.7656 - val_loss: 71856.9844 - val_mse: 71856.9844\n",
      "Epoch 359/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94066.9922 - mse: 94066.9922 - val_loss: 71855.5781 - val_mse: 71855.5781\n",
      "Epoch 360/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94069.4453 - mse: 94069.4453 - val_loss: 71854.7578 - val_mse: 71854.7578\n",
      "Epoch 361/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 94066.0156 - mse: 94066.0156 - val_loss: 71856.6875 - val_mse: 71856.6875\n",
      "Epoch 362/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94067.3203 - mse: 94067.3203 - val_loss: 71858.3750 - val_mse: 71858.3750\n",
      "Epoch 363/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 94069.7109 - mse: 94069.7109 - val_loss: 71861.1250 - val_mse: 71861.1250\n",
      "Epoch 364/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94064.3359 - mse: 94064.3359 - val_loss: 71864.8047 - val_mse: 71864.8047\n",
      "Epoch 365/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94065.9609 - mse: 94065.9609 - val_loss: 71866.8672 - val_mse: 71866.8672\n",
      "Epoch 366/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94067.8672 - mse: 94067.8672 - val_loss: 71869.8281 - val_mse: 71869.8359\n",
      "Epoch 367/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 94067.4219 - mse: 94067.4219 - val_loss: 71872.9766 - val_mse: 71872.9766\n",
      "Epoch 368/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94070.0391 - mse: 94070.0391 - val_loss: 71869.8203 - val_mse: 71869.8203\n",
      "Epoch 369/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94071.0938 - mse: 94071.0938 - val_loss: 71867.5156 - val_mse: 71867.5156\n",
      "Epoch 370/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94065.6562 - mse: 94065.6562 - val_loss: 71867.7266 - val_mse: 71867.7266\n",
      "Epoch 371/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94064.3516 - mse: 94064.3516 - val_loss: 71867.0781 - val_mse: 71867.0781\n",
      "Epoch 372/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94064.9844 - mse: 94064.9844 - val_loss: 71864.8438 - val_mse: 71864.8438\n",
      "Epoch 373/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94068.7188 - mse: 94068.7188 - val_loss: 71859.5625 - val_mse: 71859.5625\n",
      "Epoch 374/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94064.9609 - mse: 94064.9609 - val_loss: 71861.8906 - val_mse: 71861.8906\n",
      "Epoch 375/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94064.7422 - mse: 94064.7422 - val_loss: 71861.1641 - val_mse: 71861.1641\n",
      "Epoch 376/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94068.0703 - mse: 94068.0703 - val_loss: 71858.9062 - val_mse: 71858.9062\n",
      "Epoch 377/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94065.1406 - mse: 94065.1406 - val_loss: 71859.7656 - val_mse: 71859.7656\n",
      "Epoch 378/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94070.7422 - mse: 94070.7422 - val_loss: 71857.7109 - val_mse: 71857.7109\n",
      "Epoch 379/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94063.0156 - mse: 94063.0156 - val_loss: 71864.8281 - val_mse: 71864.8281\n",
      "Epoch 380/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 94058.6719 - mse: 94058.6719 - val_loss: 71870.4062 - val_mse: 71870.4062\n",
      "Epoch 381/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94061.3516 - mse: 94061.3516 - val_loss: 71875.9297 - val_mse: 71875.9297\n",
      "Epoch 382/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94058.2500 - mse: 94058.2500 - val_loss: 71888.6562 - val_mse: 71888.6562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 383/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94075.3984 - mse: 94075.3984 - val_loss: 71894.7656 - val_mse: 71894.7656\n",
      "Epoch 384/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94072.9688 - mse: 94072.9688 - val_loss: 71901.0391 - val_mse: 71901.0391\n",
      "Epoch 385/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94074.1172 - mse: 94074.1172 - val_loss: 71903.1328 - val_mse: 71903.1328\n",
      "Epoch 386/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 94075.3125 - mse: 94075.3125 - val_loss: 71900.4766 - val_mse: 71900.4766\n",
      "Epoch 387/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94074.5312 - mse: 94074.5312 - val_loss: 71897.1172 - val_mse: 71897.1172\n",
      "Epoch 388/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94075.4531 - mse: 94075.4531 - val_loss: 71886.4688 - val_mse: 71886.4688\n",
      "Epoch 389/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94082.4609 - mse: 94082.4609 - val_loss: 71893.4844 - val_mse: 71893.4844\n",
      "Epoch 390/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94074.0156 - mse: 94074.0156 - val_loss: 71897.9688 - val_mse: 71897.9688\n",
      "Epoch 391/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94077.7031 - mse: 94077.7031 - val_loss: 71893.1562 - val_mse: 71893.1562\n",
      "Epoch 392/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94069.5234 - mse: 94069.5234 - val_loss: 71892.0000 - val_mse: 71892.0000\n",
      "Epoch 393/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94065.1641 - mse: 94065.1641 - val_loss: 71887.9219 - val_mse: 71887.9219\n",
      "Epoch 394/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94072.0703 - mse: 94072.0703 - val_loss: 71881.8594 - val_mse: 71881.8594\n",
      "Epoch 395/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 94079.9922 - mse: 94079.9922 - val_loss: 71884.9844 - val_mse: 71884.9844\n",
      "Epoch 396/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 94066.1094 - mse: 94066.1094 - val_loss: 71894.2188 - val_mse: 71894.2188\n",
      "Epoch 397/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94070.7109 - mse: 94070.7109 - val_loss: 71894.6562 - val_mse: 71894.6562\n",
      "Epoch 398/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94071.8594 - mse: 94071.8594 - val_loss: 71891.2891 - val_mse: 71891.2891\n",
      "Epoch 399/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94071.8984 - mse: 94071.8984 - val_loss: 71886.3203 - val_mse: 71886.3203\n",
      "Epoch 400/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94073.7188 - mse: 94073.7188 - val_loss: 71877.8047 - val_mse: 71877.8047\n",
      "Epoch 401/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94070.0000 - mse: 94070.0000 - val_loss: 71873.3906 - val_mse: 71873.3906\n",
      "Epoch 402/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94072.2109 - mse: 94072.2109 - val_loss: 71867.9688 - val_mse: 71867.9688\n",
      "Epoch 403/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94066.7969 - mse: 94066.7969 - val_loss: 71870.1797 - val_mse: 71870.1797\n",
      "Epoch 404/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94066.0469 - mse: 94066.0469 - val_loss: 71872.8594 - val_mse: 71872.8594\n",
      "Epoch 405/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94066.9922 - mse: 94066.9922 - val_loss: 71873.0312 - val_mse: 71873.0312\n",
      "Epoch 406/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94062.8438 - mse: 94062.8438 - val_loss: 71867.1797 - val_mse: 71867.1797\n",
      "Epoch 407/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94075.1250 - mse: 94075.1250 - val_loss: 71869.7109 - val_mse: 71869.7109\n",
      "Epoch 408/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94066.4531 - mse: 94066.4531 - val_loss: 71869.2031 - val_mse: 71869.2031\n",
      "Epoch 409/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94067.9844 - mse: 94067.9844 - val_loss: 71867.6484 - val_mse: 71867.6484\n",
      "Epoch 410/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94068.7734 - mse: 94068.7734 - val_loss: 71864.3047 - val_mse: 71864.3047\n",
      "Epoch 411/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94065.9766 - mse: 94065.9766 - val_loss: 71863.6484 - val_mse: 71863.6484\n",
      "Epoch 412/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94068.4375 - mse: 94068.4375 - val_loss: 71859.9531 - val_mse: 71859.9531\n",
      "Epoch 413/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94071.7500 - mse: 94071.7500 - val_loss: 71863.9453 - val_mse: 71863.9453\n",
      "Epoch 414/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94061.2969 - mse: 94061.2969 - val_loss: 71867.5000 - val_mse: 71867.5000\n",
      "Epoch 415/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94065.3672 - mse: 94065.3672 - val_loss: 71867.3438 - val_mse: 71867.3438\n",
      "Epoch 416/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 94066.1250 - mse: 94066.1250 - val_loss: 71869.1719 - val_mse: 71869.1719\n",
      "Epoch 417/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94071.6094 - mse: 94071.6094 - val_loss: 71866.1016 - val_mse: 71866.1016\n",
      "Epoch 418/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94061.5469 - mse: 94061.5469 - val_loss: 71870.3203 - val_mse: 71870.3203\n",
      "Epoch 419/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94071.2422 - mse: 94071.2422 - val_loss: 71877.9844 - val_mse: 71877.9844\n",
      "Epoch 420/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94071.8984 - mse: 94071.8984 - val_loss: 71873.2891 - val_mse: 71873.2969\n",
      "Epoch 421/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94074.2812 - mse: 94074.2812 - val_loss: 71880.0156 - val_mse: 71880.0156\n",
      "Epoch 422/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94070.3047 - mse: 94070.3047 - val_loss: 71882.4062 - val_mse: 71882.4062\n",
      "Epoch 423/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94070.1328 - mse: 94070.1328 - val_loss: 71880.7656 - val_mse: 71880.7656\n",
      "Epoch 424/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94078.1562 - mse: 94078.1562 - val_loss: 71869.6562 - val_mse: 71869.6562\n",
      "Epoch 425/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94066.2734 - mse: 94066.2734 - val_loss: 71865.5312 - val_mse: 71865.5312\n",
      "Epoch 426/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94062.5547 - mse: 94062.5547 - val_loss: 71862.8906 - val_mse: 71862.8906\n",
      "Epoch 427/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94064.1875 - mse: 94064.1875 - val_loss: 71859.9297 - val_mse: 71859.9297\n",
      "Epoch 428/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94071.0312 - mse: 94071.0312 - val_loss: 71855.4297 - val_mse: 71855.4297\n",
      "Epoch 429/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94066.8438 - mse: 94066.8438 - val_loss: 71857.1875 - val_mse: 71857.1875\n",
      "Epoch 430/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94066.0234 - mse: 94066.0234 - val_loss: 71857.0156 - val_mse: 71857.0156\n",
      "Epoch 431/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94066.9688 - mse: 94066.9688 - val_loss: 71857.6328 - val_mse: 71857.6328\n",
      "Epoch 432/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94068.3828 - mse: 94068.3828 - val_loss: 71861.0703 - val_mse: 71861.0703\n",
      "Epoch 433/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94062.6328 - mse: 94062.6328 - val_loss: 71867.1875 - val_mse: 71867.1875\n",
      "Epoch 434/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94071.7891 - mse: 94071.7891 - val_loss: 71870.1641 - val_mse: 71870.1641\n",
      "Epoch 435/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94066.2344 - mse: 94066.2344 - val_loss: 71870.9375 - val_mse: 71870.9375\n",
      "Epoch 436/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 94067.2891 - mse: 94067.2891 - val_loss: 71869.4609 - val_mse: 71869.4609\n",
      "Epoch 437/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 94068.8828 - mse: 94068.8828 - val_loss: 71877.2812 - val_mse: 71877.2812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 438/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94065.7891 - mse: 94065.7891 - val_loss: 71880.1094 - val_mse: 71880.1094\n",
      "Epoch 439/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 94067.5078 - mse: 94067.5078 - val_loss: 71882.9531 - val_mse: 71882.9531\n",
      "Epoch 440/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94069.7422 - mse: 94069.7422 - val_loss: 71880.8516 - val_mse: 71880.8516\n",
      "Epoch 441/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94065.6094 - mse: 94065.6094 - val_loss: 71883.0469 - val_mse: 71883.0469\n",
      "Epoch 442/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94069.1719 - mse: 94069.1719 - val_loss: 71884.4688 - val_mse: 71884.4688\n",
      "Epoch 443/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94068.5625 - mse: 94068.5625 - val_loss: 71876.9766 - val_mse: 71876.9766\n",
      "Epoch 444/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 94069.3906 - mse: 94069.3906 - val_loss: 71878.1953 - val_mse: 71878.1953\n",
      "Epoch 445/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94074.5391 - mse: 94074.5391 - val_loss: 71875.2344 - val_mse: 71875.2344\n",
      "Epoch 446/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94070.1875 - mse: 94070.1875 - val_loss: 71869.7422 - val_mse: 71869.7422\n",
      "Epoch 447/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 94064.0156 - mse: 94064.0156 - val_loss: 71868.0391 - val_mse: 71868.0391\n",
      "Epoch 448/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94064.7500 - mse: 94064.7500 - val_loss: 71864.9844 - val_mse: 71864.9844\n",
      "Epoch 449/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94064.2656 - mse: 94064.2656 - val_loss: 71859.1172 - val_mse: 71859.1172\n",
      "Epoch 450/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 94067.4062 - mse: 94067.4062 - val_loss: 71854.5625 - val_mse: 71854.5625\n",
      "Epoch 451/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94066.5625 - mse: 94066.5625 - val_loss: 71853.9141 - val_mse: 71853.9141\n",
      "Epoch 452/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94068.2344 - mse: 94068.2344 - val_loss: 71853.9141 - val_mse: 71853.9141\n",
      "Epoch 453/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 94067.6953 - mse: 94067.6953 - val_loss: 71854.2812 - val_mse: 71854.2734\n",
      "Epoch 454/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94074.0391 - mse: 94074.0391 - val_loss: 71858.6094 - val_mse: 71858.6094\n",
      "Epoch 455/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94061.7266 - mse: 94061.7266 - val_loss: 71863.2422 - val_mse: 71863.2422\n",
      "Epoch 456/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94067.1016 - mse: 94067.1016 - val_loss: 71875.0938 - val_mse: 71875.0938\n",
      "Epoch 457/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 94064.3594 - mse: 94064.3594 - val_loss: 71878.0938 - val_mse: 71878.0938\n",
      "Epoch 458/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94071.2891 - mse: 94071.2891 - val_loss: 71881.9141 - val_mse: 71881.9141\n",
      "Epoch 459/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94068.1328 - mse: 94068.1328 - val_loss: 71880.3281 - val_mse: 71880.3281\n",
      "Epoch 460/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94082.4766 - mse: 94082.4766 - val_loss: 71873.2656 - val_mse: 71873.2656\n",
      "Epoch 461/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94065.9766 - mse: 94065.9766 - val_loss: 71877.3047 - val_mse: 71877.3047\n",
      "Epoch 462/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94066.7109 - mse: 94066.7109 - val_loss: 71878.8203 - val_mse: 71878.8203\n",
      "Epoch 463/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94064.7656 - mse: 94064.7656 - val_loss: 71880.8125 - val_mse: 71880.8125\n",
      "Epoch 464/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94067.8203 - mse: 94067.8203 - val_loss: 71881.2188 - val_mse: 71881.2188\n",
      "Epoch 465/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94067.2266 - mse: 94067.2266 - val_loss: 71880.6953 - val_mse: 71880.6953\n",
      "Epoch 466/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94068.4375 - mse: 94068.4375 - val_loss: 71875.3203 - val_mse: 71875.3203\n",
      "Epoch 467/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94083.0625 - mse: 94083.0625 - val_loss: 71890.4609 - val_mse: 71890.4609\n",
      "Epoch 468/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94091.2891 - mse: 94091.2891 - val_loss: 71884.9062 - val_mse: 71884.9062\n",
      "Epoch 469/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94094.2500 - mse: 94094.2500 - val_loss: 71902.1719 - val_mse: 71902.1719\n",
      "Epoch 470/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94075.1875 - mse: 94075.1875 - val_loss: 71903.5469 - val_mse: 71903.5469\n",
      "Epoch 471/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94083.2344 - mse: 94083.2344 - val_loss: 71914.7891 - val_mse: 71914.7891\n",
      "Epoch 472/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94080.6484 - mse: 94080.6484 - val_loss: 71910.1562 - val_mse: 71910.1562\n",
      "Epoch 473/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 94077.5781 - mse: 94077.5781 - val_loss: 71903.2109 - val_mse: 71903.2109\n",
      "Epoch 474/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94078.5078 - mse: 94078.5078 - val_loss: 71905.2656 - val_mse: 71905.2656\n",
      "Epoch 475/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94076.1172 - mse: 94076.1172 - val_loss: 71904.0078 - val_mse: 71904.0078\n",
      "Epoch 476/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94070.4141 - mse: 94070.4141 - val_loss: 71899.3750 - val_mse: 71899.3750\n",
      "Epoch 477/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94071.9141 - mse: 94071.9141 - val_loss: 71895.3203 - val_mse: 71895.3203\n",
      "Epoch 478/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 94073.9531 - mse: 94073.9531 - val_loss: 71890.1250 - val_mse: 71890.1250\n",
      "Epoch 479/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94085.3672 - mse: 94085.3672 - val_loss: 71884.9688 - val_mse: 71884.9688\n",
      "Epoch 480/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94069.0469 - mse: 94069.0469 - val_loss: 71892.0859 - val_mse: 71892.0859\n",
      "Epoch 481/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94069.5391 - mse: 94069.5391 - val_loss: 71904.2344 - val_mse: 71904.2344\n",
      "Epoch 482/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94077.1172 - mse: 94077.1172 - val_loss: 71909.4844 - val_mse: 71909.4844\n",
      "Epoch 483/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94078.1328 - mse: 94078.1328 - val_loss: 71915.0938 - val_mse: 71915.0938\n",
      "Epoch 484/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94077.7109 - mse: 94077.7109 - val_loss: 71922.5156 - val_mse: 71922.5156\n",
      "Epoch 485/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 94091.5938 - mse: 94091.5938 - val_loss: 71931.6250 - val_mse: 71931.6250\n",
      "Epoch 486/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 94086.5391 - mse: 94086.5391 - val_loss: 71926.8516 - val_mse: 71926.8516\n",
      "Epoch 487/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94085.3750 - mse: 94085.3750 - val_loss: 71925.9766 - val_mse: 71925.9766\n",
      "Epoch 488/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94090.4219 - mse: 94090.4219 - val_loss: 71912.9844 - val_mse: 71912.9844\n",
      "Epoch 489/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94078.5938 - mse: 94078.5938 - val_loss: 71911.3047 - val_mse: 71911.3047\n",
      "Epoch 490/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94082.0703 - mse: 94082.0703 - val_loss: 71899.4453 - val_mse: 71899.4453\n",
      "Epoch 491/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94070.2891 - mse: 94070.2891 - val_loss: 71892.2188 - val_mse: 71892.2188\n",
      "Epoch 492/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94067.7734 - mse: 94067.7734 - val_loss: 71884.0078 - val_mse: 71884.0078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 493/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 94081.9062 - mse: 94081.9062 - val_loss: 71876.6406 - val_mse: 71876.6406\n",
      "Epoch 494/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94084.2656 - mse: 94084.2656 - val_loss: 71884.0859 - val_mse: 71884.0859\n",
      "Epoch 495/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94067.6094 - mse: 94067.6094 - val_loss: 71883.2344 - val_mse: 71883.2344\n",
      "Epoch 496/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94072.3203 - mse: 94072.3203 - val_loss: 71886.6016 - val_mse: 71886.6016\n",
      "Epoch 497/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94073.4766 - mse: 94073.4766 - val_loss: 71885.9219 - val_mse: 71885.9219\n",
      "Epoch 498/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94075.4922 - mse: 94075.4922 - val_loss: 71890.4219 - val_mse: 71890.4219\n",
      "Epoch 499/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94071.6406 - mse: 94071.6406 - val_loss: 71892.5781 - val_mse: 71892.5781\n",
      "Epoch 500/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94074.1797 - mse: 94074.1797 - val_loss: 71907.2812 - val_mse: 71907.2812\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x=x_train,y=y_train,validation_data=(x_test,y_test),epochs=500,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76f00001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 71907.2812 - mse: 71907.2812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[71907.28125, 71907.28125]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f987f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fed140ac760>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'],label='Train')\n",
    "plt.plot(history.history['val_loss'],label='Validation')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Model Loss')\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdd2a39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
